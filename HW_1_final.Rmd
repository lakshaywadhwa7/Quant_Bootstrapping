---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
plot(cars)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
```{r}

```


Problem B.1
(a) State why a  ????2  confidence interval is not valid in this context


Because the underlying distribution is not normal in this case and chi square distribution with n <30 can only be invoked if the underlying distribution is normal.








(b) Generate a sample of size  ????=8  from  ??(????=1,????=1/3)  and calculate the true population standard deviation (in this example, we are generating data so that we can see how well our estimation procedure will do).

```{r}
# random variables from gamma distribution
set.seed(1)
n<-8
alpha<-1
beta<-3
rsg1<-rgamma(n,alpha,scale=beta)

#standard deviation
sd(rsg1)


```

(c) Generate  ????=200  bootstrap samples from the above sample. Print the dimension, and articulate what each row/column represents. Avoid loops! (HINT: use the replicate() function.)

```{r}
# generating 200 bootsrapping samples out of gamma distribution
B=200
bs=replicate(B,sample(rsg1,n,replace=TRUE));
dim(bs)
#Each column represent a bootstrap sample which can be used to estimate the thetastarhat which is approximating the Thetahat which is in turn the estimate of the true population parameter.
#Here are total 8 rows and 200 columns.     
```




(d) Calculate and print the MLE of  ????  for the original sample. Denote this as  ????^ . Then, calculate the MLE of  ????  for each bootstrap sample. Denote this as  ????^??????? , for  ????=1,...,???? . Avoid loops! (HINT: use the apply() function.) Display a histogram of these values.

```{r}
LLab <- function(pars,X){
# log likelihood for Gamma(alpha,scale=beta)
# X is data
alpha <- pars[1]
beta <- pars[2]
-sum(dgamma(X,alpha,scale=beta,log=TRUE))
}


```




```{r}
pars<-c(4,1)

mle<-optim(pars,LLab,X=rsg1,hessian=TRUE)
a<-mle$par[1]
b<-mle$par[2]


theta_hat<-sqrt(a/(b^2))
theta_hat
```
```{r}

dim(bs)
```


```{r}



```







```{r}
pars<-c(4,1)
mle_1<-vector()
theta_hat_star<-rep(0,200)
for (i in 1:200)
{
mle_1<-optim(pars,LLab,X=bs[,i],hessian=TRUE)
a<-mle_1$par[1]
b<-mle_1$par[2]
theta_hat_star[i]<-sqrt(a/(b^2))
}

#thetahatstar1[i]<-apply(X=bs[,i],MARGIN=2,FUN=mle)

```



```{r}
quantile(theta_hat_star,c(0.05,0.95))
```


Problem B.2
Thus far, we've been looking at the nonparametric bootstrap. In this problem, we look at the parametric bootstrap as a way of estimating the bias and variance of an estimator ????^=????¯2 of ????=????2 (in problem A.1 you calculated these values exactly).

(a) Generate ????1,...,????20???????????????????(????=2,????2=1), and then forget that you know ???? and ????2. Find the sample mean and sample variance.


```{r}
n<-20
u<-2
sigma_2<-1
sigma<-sqrt(sigma_2)
rnorm1<-rnorm(n,mean=u,sd=sigma)
sd_sample<-sd(rnorm1)
mean_sample<-mean(rnorm1)

```

(b) Define  ????^  to be the distribution of the variable  ????????  in the population with the sample estimates plugged in for the unknown population parameters. Write down  ????^  based on the data generated in (a).













(c)


```{r}
B<-500
bs<-replicate(B,sample(rnorm1,n,replace=TRUE))

```

```{r}

col_mean<-colMeans(bs)
col_value<-col_mean^2
```

(d) Compute an estimate of the bias:
????^(????^)???1???????????=1????????^??????????????¯2.



```{r}
x_bar_2<-mean_sample^2
Bias_sample<-mean(col_value)-x_bar_2
Bias_sample
```

```{r}
Bias_original<-sd_sample^2/20
Bias_original
```

(e) Compute an estimate of the variance:



```{r}
var_value<-rep(0,B)
theta_bar<-mean(col_value)
for (i in  1:B)
{
  var_value[i]<-(col_value[i]-theta_bar)^2
}

```

```{r}
var_final<-sum(var_value)/(B-1)
var_final
```

```{r}
sd_sample
```




B.4
Load the data frame Animals from the MASS package. Construct a 95% bootstrap percentile confidence interval for the correlation coefficient between  log(????????????????????)  and  log(????????????????) . A percentile confidence interval is simply
[????^???????/2,????^???1???????/2],
 
where  ????^???????/2  is the  ????/2  quantile of the bootstrap distribution. (We note that in many cases, this confidence interval is not as accurate as the pivot interval discussed in class.)


```{r}
install.packages("MASS")
```

```{r}
library(MASS)
```

```{r}

head(Animals)

```

```{r}

a<-Animals
B<-200
corr<-rep(0,200)
for (i in 1:B)
{
d<-a[sample(nrow(a), 3), ]
corr[i]<-cor(d$body,d$brain)  
}

```





```{r}
quantile(corr,c(0.025,0.975))
```

